---
layout: page
permalink: /challenge
---

<h2>Chart Question Answering Challenge</h2>

The CQA challenge includes 3 levels of perception: from  low-level visualization building blocks to semantic reasoning that requires text extraction.<br><br>

<h3>Low-level:</h3> Can your model measure Cleveland and McGill's 1984 Angle and Length stimuli? Does your model succeed even in cases of x-position, y-position, and stroke width variations? What about Cleveland and McGill's 1985 images?

<img src='gfx/angle.png' style='height:100px'><img src='gfx/length.png' style='height:100px'><img src='gfx/4angle.png' style='height:99px;border:1px solid lightgray;'><img src='gfx/4length.png' style='height:99px;border:1px solid lightgray;'><br>
<a href="https://drive.google.com/file/d/1X1o8Mkn3t4rnZvAnUWABJMhByG8GFNc8/view?usp=sharing" target="_blank" class='lightgray'>Training and test sets now available!</a>

<br><br>

<h3>Mid-level:</h3> What about simple bar and pie charts? Can your model successfully compare ratios - even with stroke width variations?

<img src='gfx/wide_lev2.png' style='height:100px'><br>
<a href="https://drive.google.com/file/d/1o6EMJjpiLnvVzftOB_FJlzYid-QbJI6N/view?usp=sharing" target="_blank" class='lightgray'>Training and test sets now available!</a>

<br><br>

<h3>High-level:</h3> Now, images contain textual information. Can your model answer questions regarding the data? Can it generalize between apples and oranges? 


<img src='gfx/wide_lev3.png' style='height:100px'><br>
<a href="https://drive.google.com/file/d/1zyqj6M5ug-57ohxmgTogCMrxb33_7w8x/view?usp=sharing" target="_blank" class='lightgray'>Training and test sets now available!</a>
