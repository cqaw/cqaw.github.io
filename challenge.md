---
layout: page
permalink: /challenge
---

<h2>Chart Question Answering Challenge</h2>

The CQA challenge includes 3 levels of perception: from  low-level visualization building blocks to semantic reasoning that requires text extraction.<br><br>

<h3>Low-level:</h3> Can your model measure Cleveland and McGill's 1984 Angle and Length stimuli? Does your model succeed even in cases of x-position, y-position, and stroke width variations? What about Cleveland and McGill's 1985 images?

<img src='gfx/angle.png' style='height:100px'><img src='gfx/length.png' style='height:100px'><img src='gfx/4angle.png' style='height:99px;border:1px solid lightgray;'><img src='gfx/4length.png' style='height:99px;border:1px solid lightgray;'><br>
<a class='lightgray'>Training and test sets coming very soon!</a>

<br><br>

<h3>Mid-level:</h3> What about simple bar and pie charts? Can your model successfully compare ratios - even with stroke width variations?

<img src='gfx/midlevel.png' style='height:100px'><br>
<a class='lightgray'>Training and test sets coming very soon!</a>

<br><br>

<h3>High-level:</h3> Now, images contain textual information. Can your model answer questions regarding the data?

Details to be announced.
<br>
<a class='lightgray'>Training and test sets coming very soon!</a>


